{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e139a46d-1266-47d4-8f8c-223b526db2f8",
   "metadata": {},
   "source": [
    "# Kafka Producer Test\n",
    "1. Read this CSV with headers using spark.\n",
    "2. Publish these records into Kafka in streaming fashion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db61a056-198e-4401-b15b-8bde9c44d3cb",
   "metadata": {},
   "source": [
    "### Test dummy (practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9e1b78-92c5-4d04-985e-3574e1ef4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit, to_json, struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5582241e-1b68-49bd-86f9-a719bf8eb937",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SimpleKafkaProducerTest\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.5\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "603ec679-d033-42f5-8bb1-0e4f876955e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eb168df-55c9-4294-8451-3916d5720131",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_df = spark.readStream \\\n",
    "    .format(\"rate\") \\\n",
    "    .option(\"rowsPerSecond\", 1) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c9f7fd-1832-4578-8e49-d5abc9657d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = rate_df.select(\n",
    "    to_json(\n",
    "        struct(\n",
    "            lit(\"Test Message\").alias(\"message\"),\n",
    "            rate_df[\"value\"].alias(\"id\")\n",
    "        )\n",
    "    ).alias(\"value\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a9ec7ba-75d6-4c60-9427-dba87594da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_bootstrap_servers = \"kafka:9092\"  \n",
    "topic = \"test-topic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efc88e5f-b949-4a82-9d5e-0fb5f1ee1a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = test_df.writeStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "    .option(\"topic\", topic) \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/kafka_test_checkpoint\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d41d55f-c25d-40d6-bf4c-0ed5dc3cf442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Simple test streaming producer is running. Check your Kafka consumer for messages.\")\n",
    "# query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834b89f6-8838-4b32-b778-93859d9ff5a3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Kafka_Producer Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b65ca608-d5f1-4d73-9029-5a45698b8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5340a99-f9cc-4156-94a1-a48affa4847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaProducer\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.5\") \\\n",
    "    .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "205bb00d-ac29-4c23-bdf9-bc5c5a4f671e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa536191-52b8-4c3e-8446-6c9245ca70f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Preview:\n",
      "+----------------+-------------------+----------------+-----------------------------+------------------+\n",
      "|       Date/Time|LV ActivePower (kW)|Wind Speed (m/s)|Theoretical_Power_Curve (KWh)|Wind Direction (°)|\n",
      "+----------------+-------------------+----------------+-----------------------------+------------------+\n",
      "|01 01 2018 00:00|   380.047790527343|5.31133604049682|             416.328907824861|  259.994903564453|\n",
      "|01 01 2018 00:10|    453.76919555664|5.67216682434082|             519.917511061494|   268.64111328125|\n",
      "|01 01 2018 00:20|   306.376586914062|5.21603679656982|             390.900015810951|  272.564788818359|\n",
      "|01 01 2018 00:30|   419.645904541015|5.65967416763305|             516.127568975674|  271.258087158203|\n",
      "|01 01 2018 00:40|   380.650695800781|5.57794094085693|             491.702971953588|  265.674285888671|\n",
      "+----------------+-------------------+----------------+-----------------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Static CSV row count: 99\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/data/dataset.csv\", header=True, inferSchema=True)\n",
    "print(\"CSV Preview:\")\n",
    "df.show(5)\n",
    "print(\"Static CSV row count:\", df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caf6b36c-5c63-4e88-91f4-e88f2155268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_idx_row(row, index):\n",
    "    row_dict = row.asDict()\n",
    "    row_dict[\"row_id\"] = index\n",
    "    return Row(**row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "990fd795-5f56-4e9e-ad00-c18c2d5d33f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static CSV Input DF Schema:\n",
      "root\n",
      " |-- Date/Time: string (nullable = true)\n",
      " |-- LV ActivePower (kW): double (nullable = true)\n",
      " |-- Wind Speed (m/s): double (nullable = true)\n",
      " |-- Theoretical_Power_Curve (KWh): double (nullable = true)\n",
      " |-- Wind Direction (°): double (nullable = true)\n",
      " |-- row_id: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = df.rdd.zipWithIndex().map(lambda x: add_idx_row(x[0], x[1]))\n",
    "new_schema = df.schema.add(\"row_id\", LongType())\n",
    "new_df = spark.createDataFrame(rdd, schema=new_schema)\n",
    "\n",
    "print(\"Static CSV Input DF Schema:\")\n",
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75a01280-78b9-476e-94b4-ae5a87bce27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = spark.readStream \\\n",
    "    .format(\"rate\") \\\n",
    "    .option(\"rowsPerSecond\", 10) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11ae2ee3-d011-4122-bb97-fc3e405432a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = streaming_df.withColumnRenamed(\"value\", \"row_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f0ea8dd0-bd03-48bc-a758-997192a6976d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static CSV row count: 99\n"
     ]
    }
   ],
   "source": [
    "print(\"Static CSV row count:\", new_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee58c210-216f-42ed-b999-3492b20a7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_df = streaming_df.filter(col(\"row_id\") < lit(new_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f74546af-f89f-41c7-bd0f-870bdacd8e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined Streaming DF Schema:\n",
      "root\n",
      " |-- row_id: long (nullable = true)\n",
      " |-- Date/Time: string (nullable = true)\n",
      " |-- LV ActivePower (kW): double (nullable = true)\n",
      " |-- Wind Speed (m/s): double (nullable = true)\n",
      " |-- Theoretical_Power_Curve (KWh): double (nullable = true)\n",
      " |-- Wind Direction (°): double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_type = \"left_outer\"\n",
    "joined_df = streaming_df.join(new_df, on=\"row_id\", how=join_type).drop(\"timestamp\")\n",
    "\n",
    "print(\"Joined Streaming DF Schema:\")\n",
    "joined_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52a7a9d3-d0e4-4a8a-9ac3-69bb6a45c0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kafka Output DF Schema (JSON):\n",
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_output_df = joined_df.select(\n",
    "    to_json(struct([col(x) for x in joined_df.columns])).alias(\"value\")\n",
    ")\n",
    "\n",
    "print(\"Kafka Output DF Schema (JSON):\")\n",
    "kafka_output_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19962797-8520-4ee9-b156-d11fb3a25eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming data to console sink now... (Press Ctrl+C to stop)\n"
     ]
    }
   ],
   "source": [
    "console_query = kafka_output_df.writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n",
    "\n",
    "print(\"Streaming data to console sink now... (Press Ctrl+C to stop)\")\n",
    "console_query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d66b52c-0cf7-4bfe-9ddc-efff02859d59",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- verify on consumer console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3626b5b-b221-4ce2-86b7-96ca9e5f6196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
