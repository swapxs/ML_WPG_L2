{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a28580a-c002-4015-ac08-692a09edfcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession as ss\n",
    "from pyspark.sql.types import (\n",
    "    StructType as st,\n",
    "    StructField as sf,\n",
    "    StringType as srt,\n",
    "    DoubleType as dt,\n",
    "    LongType as lt\n",
    ")\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    from_json,\n",
    "    col,\n",
    "    to_date,\n",
    "    to_timestamp,\n",
    "    current_date,\n",
    "    current_timestamp,\n",
    "    lit,\n",
    "    map_from_arrays,\n",
    "    array,\n",
    "    date_format\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82f5e28-c453-4dcf-8750-ba8e88f247e8",
   "metadata": {},
   "source": [
    "Create a SparkSession named \"KafkaSubscriber\"  \n",
    "Master is the Spark standalone cluster at 'spark-master:7077'  \n",
    "Include both the spark-sql-kafka package and delta-spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e8e56db-a4ab-4099-b477-7119af4b1337",
   "metadata": {},
   "outputs": [],
   "source": [
    "sprk = ss.builder \\\n",
    "    .appName(\"KafkaSubscriber\") \\\n",
    "    .master(\"spark://spark-master:7077\") \\\n",
    "    .config(\n",
    "        \"spark.jars.packages\", \n",
    "        \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.5,\"\n",
    "        \"io.delta:delta-spark_2.12:3.3.0\"\n",
    "    ) \\\n",
    "    .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b252c7-4f13-4b6c-9568-4733a340f5a2",
   "metadata": {},
   "source": [
    "Define the schema that matches the JSON structure produced by `Kafka_Producer.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac120d09-c8cf-4d40-9b94-044b1b53ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = st([\n",
    "    sf(\"Date/Time\", srt(), True),\n",
    "    sf(\"LV ActivePower (kW)\", dt(), True),\n",
    "    sf(\"Wind Speed (m/s)\", dt(), True),\n",
    "    sf(\"Theoretical_Power_Curve (KWh)\", dt(), True),\n",
    "    sf(\"Wind Direction (°)\", dt(), True),\n",
    "    sf(\"row_id\", lt(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf7d250-ec63-4365-b151-fb90a8f4d55e",
   "metadata": {},
   "source": [
    "Create a streaming DataFrame from Kafka:\n",
    "- `kafka.bootstrap.servers` points to the internal Kafka address\n",
    "- `subscribe` is set to `xenon-topic`\n",
    "- `startingOffsets = earliest` means we read all messages from the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81bc65c2-d2c5-4dd0-9c0e-26e20eaa7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_df = sprk.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"xenon-topic\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"failOnDataLoss\", \"false\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b2695c-1984-4545-b886-37b1c2c539a1",
   "metadata": {},
   "source": [
    "Parse the `value` field (binary) as a string and apply the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a55182-90da-402f-8cf8-992ddb08499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = kafka_df.select(\n",
    "    from_json(\n",
    "        col(\"value\").cast(\"string\"),\n",
    "        json_schema\n",
    "    ).alias(\"jsonData\")\n",
    ").select(\"jsonData.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb21984d-ce2c-4881-a156-27ebb84f36c3",
   "metadata": {},
   "source": [
    "Build the final DataFrame with the required columns:  \n",
    "`signal_date`, `signal_ts`, `create_date`, `create_ts`, `signals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c53da54e-2aa3-4db6-9f5e-e5e5fdd43daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.select(\n",
    "    # Convert to signal_date\n",
    "    to_date(\n",
    "        to_timestamp(col(\"Date/Time\"), \"dd MM yyyy HH:mm\"),\n",
    "        \"yyyy-MM-dd\"\n",
    "    ).alias(\"signal_date\"),\n",
    "\n",
    "    # Force correct timestamp format with 'T' and store as string\n",
    "    date_format(\n",
    "        to_timestamp(col(\"Date/Time\"), \"dd MM yyyy HH:mm\"),\n",
    "        \"yyyy-MMdd'T'HH:mm:ss\"\n",
    "    ).alias(\"signal_ts\"),\n",
    "\n",
    "    # Capture processing time\n",
    "    current_date().alias(\"create_date\"),\n",
    "    current_timestamp().alias(\"create_ts\"),\n",
    "\n",
    "    # Signals as a map\n",
    "    map_from_arrays(\n",
    "        array(\n",
    "            lit(\"LV ActivePower (kW)\"),\n",
    "            lit(\"Wind Speed (m/s)\"),\n",
    "            lit(\"Theoretical_Power_Curve (KWh)\"),\n",
    "            lit(\"Wind Direction (°)\")\n",
    "        ),\n",
    "        array(\n",
    "            col(\"LV ActivePower (kW)\").cast(\"string\"),\n",
    "            col(\"Wind Speed (m/s)\").cast(\"string\"),\n",
    "            col(\"Theoretical_Power_Curve (KWh)\").cast(\"string\"),\n",
    "            col(\"Wind Direction (°)\").cast(\"string\")\n",
    "        )\n",
    "    ).alias(\"signals\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e97f0c7-d562-4f36-9fae-c38250378c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- signal_date: date (nullable = true)\n",
      " |-- signal_ts: string (nullable = true)\n",
      " |-- create_date: date (nullable = false)\n",
      " |-- create_ts: timestamp (nullable = false)\n",
      " |-- signals: map (nullable = false)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdc1886-c3ad-45ca-ae0e-9c161a7fc536",
   "metadata": {},
   "source": [
    "Write the stream to a Delta table in \"append\" mode  \n",
    "`trigger(once=True)` processes all available messages and stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6f95002-e1ac-40fb-8329-00be5e813ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7600b0d854c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"checkpointLocation\", \"/tmp/delta_kafka_subscriber_checkpoint\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start(\"/data/delta_output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37684492-bff1-4318-997c-bdb18aa4033a",
   "metadata": {},
   "source": [
    "Block until the streaming job completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a6305b1-233b-48e7-aa92-54b2574a7764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|signal_ts         |\n",
      "+------------------+\n",
      "|2018-0101T10:50:00|\n",
      "|2018-0101T00:00:00|\n",
      "|2018-0101T03:10:00|\n",
      "|2018-0101T09:00:00|\n",
      "|2018-0101T04:20:00|\n",
      "+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sprk.read.format(\"delta\").load(\"/data/delta_output\")\n",
    "df.select(\"signal_ts\").show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce204a0d-f639-40bd-9071-b5377992aee0",
   "metadata": {},
   "source": [
    "Stop Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c1dfb0-1d3d-4de8-b392-dfd3c433dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sprk.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f010a99-fa37-4524-a07b-11c573c211e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
